# Ghost Writer Configuration

# Database settings
database:
  path: "data/database/ghost_writer.db"

# OCR Provider Configuration
ocr:
  # Options: "tesseract", "cloud_vision", "hybrid"
  default_provider: "hybrid"
  
  providers:
    tesseract:
      # Tesseract OCR Engine settings
      config: "--oem 3 --psm 6"  # OCR Engine Mode 3, Page Segmentation Mode 6
      confidence_threshold: 60   # Minimum confidence to accept results
      preprocessing:
        enhance_contrast: true
        remove_noise: true
        deskew: true
    
    google_vision:
      # Google Cloud Vision API settings
      credentials_path: "config/google_cloud_credentials.json"
      language_hints: ["en"]
      confidence_threshold: 80
      features:
        - "DOCUMENT_TEXT_DETECTION"
      cost_per_image: 0.0015
    
    gpt4_vision:
      # OpenAI GPT-4 Vision API settings
      api_key_env: "OPENAI_API_KEY"
      model: "gpt-4o"
      confidence_threshold: 85
      max_tokens: 4000
      cost_per_image: 0.01
      system_prompt: |
        You are a precise OCR system. Transcribe this handwritten text exactly as written.
        Preserve the original structure, line breaks, and formatting.
        If text is unclear, mark it with [unclear] but don't guess.
        Do not add content that wasn't written.
    
    hybrid:
      # Intelligent routing between providers
      provider_priority: ["tesseract", "google_vision", "gpt4_vision"]
      confidence_thresholds:
        tesseract: 75               # Switch if tesseract confidence < 75%
        google_vision: 85           # Switch if google_vision confidence < 85%
      cost_limit_per_day: 5.00     # Max daily spend on premium OCR ($)
      prefer_local: true            # Try local providers first
      fallback_enabled: true       # Always fall back to tesseract
      quality_mode: "balanced"     # Options: "fast", "balanced", "premium"

# Embedding settings for semantic search
embeddings:
  model_name: "all-MiniLM-L6-v2"    # Sentence transformer model
  dimension: 384                     # Vector dimension
  batch_size: 32                     # Batch processing size
  cache_embeddings: true             # Cache computed embeddings

# FAISS vector search settings
faiss:
  index_path: "data/faiss_index/"
  index_type: "IndexFlatIP"          # Inner product similarity
  rebuild_threshold: 100             # Rebuild index after N new embeddings
  search_k: 5                        # Default number of results to return

# Local LLM settings (Ollama)
llm:
  model: "llama3:latest"             # Use existing model
  temperature: 0.7                   # Creativity vs consistency
  max_tokens: 1000                   # Maximum response length
  timeout: 120                       # Request timeout in seconds
  system_prompt: |
    You are a writing assistant helping to expand and develop handwritten notes into coherent content.
    Maintain the original author's voice and style. Be concise but thorough.

# Style corpus settings
style:
  corpus_path: "data/style_corpus/"
  min_examples: 3                    # Minimum style examples needed
  max_context_length: 2000          # Max chars to include in style context
  similarity_threshold: 0.7          # Minimum similarity for style matching

# Processing settings
processing:
  max_retries: 3                     # Retry failed operations
  timeout_seconds: 30                # Default operation timeout
  batch_size: 10                     # Process files in batches
  watch_interval: 5                  # File watching interval (seconds)
  
# Logging configuration
logging:
  level: "INFO"                      # DEBUG, INFO, WARNING, ERROR
  file_path: "data/logs/ghost_writer.log"
  max_file_size: "10MB"
  backup_count: 5
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Cost monitoring
cost_monitoring:
  daily_budget: 5.00                 # Daily budget limit ($)
  alert_thresholds: [0.5, 0.75, 0.9] # Alert at 50%, 75%, 90% of budget
  track_usage: true                  # Enable usage tracking
  monthly_report: true               # Generate monthly cost reports

# File processing
files:
  input_extensions: [".png", ".jpg", ".jpeg", ".note"]
  watch_directories: ["data/notes/"]
  archive_processed: true            # Move processed files to archive
  archive_path: "data/archive/"

# Supernote Cloud Integration
supernote:
  enabled: true                      # Enable Supernote Cloud sync
  email_env: "SUPERNOTE_EMAIL"       # Environment variable for account email
  password_env: "SUPERNOTE_PASSWORD" # Environment variable for account password
  access_token_env: "SUPERNOTE_ACCESS_TOKEN"   # Environment variable for access token
  refresh_token_env: "SUPERNOTE_REFRESH_TOKEN" # Environment variable for refresh token
  device_id_env: "SUPERNOTE_DEVICE_ID"         # Environment variable for device ID
  sync_interval: 3600               # Sync interval in seconds (1 hour)
  local_sync_dir: "data/supernote_sync/"  # Local directory for synced files
  auto_process: true                # Automatically process downloaded files
  file_types: ["note", "pdf"]       # File types to sync from cloud
  
# Search settings
search:
  default_limit: 5                   # Default number of search results
  min_similarity: 0.3               # Minimum similarity for results
  include_metadata: true             # Include OCR provider info in results
  fallback_to_text: true            # Use text search if vector search fails